{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-26T11:06:56.554325Z",
     "start_time": "2020-08-26T11:06:54.156943Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-26T11:06:57.521187Z",
     "start_time": "2020-08-26T11:06:56.555280Z"
    }
   },
   "outputs": [],
   "source": [
    "is_cuda = False\n",
    "if torch.cuda.is_available():\n",
    "    is_cuda = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-26T11:06:59.468224Z",
     "start_time": "2020-08-26T11:06:59.465230Z"
    }
   },
   "outputs": [],
   "source": [
    "path = 'C:/Users/Yeonkang/Desktop/Deep_Learning/Image_Recognition/Vanilla_CNN/Python/data/101_ObjectCategories/dataset'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Dataset can be downloaded [here](https://www.kaggle.com/c/dogs-vs-cats/data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-26T11:07:00.385226Z",
     "start_time": "2020-08-26T11:07:00.253546Z"
    }
   },
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import os\n",
    "\n",
    "files = glob(os.path.join(path, '*/*.jpg'))\n",
    "print(f'Total no of images {len(files)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-26T11:07:01.197860Z",
     "start_time": "2020-08-26T11:07:01.193870Z"
    }
   },
   "outputs": [],
   "source": [
    "no_of_images = 8677"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determine size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-26T11:07:25.066938Z",
     "start_time": "2020-08-26T11:07:24.665783Z"
    }
   },
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "null_transform = transforms.Compose([transforms.ToTensor()])\n",
    "data = ImageFolder(path, null_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-26T09:45:47.793895Z",
     "start_time": "2020-08-26T09:45:15.883288Z"
    }
   },
   "outputs": [],
   "source": [
    "height,width = [],[]\n",
    "\n",
    "for i in range(len(data)):\n",
    "    temp1 = data[i][0].shape[1]\n",
    "    temp2 = data[i][0].shape[2]\n",
    "    height.append(temp1)\n",
    "    width.append(temp2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-26T09:45:47.970423Z",
     "start_time": "2020-08-26T09:45:47.794892Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.hist(height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-26T09:45:48.092125Z",
     "start_time": "2020-08-26T09:45:47.972418Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.hist(width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-26T09:45:48.096120Z",
     "start_time": "2020-08-26T09:45:48.093095Z"
    }
   },
   "outputs": [],
   "source": [
    "def imshow(inp):\n",
    "    inp = inp.numpy().transpose((1,2,0))\n",
    "    inp = np.clip(inp,0,1)\n",
    "    plt.imshow(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-26T09:45:48.278641Z",
     "start_time": "2020-08-26T09:45:48.097114Z"
    }
   },
   "outputs": [],
   "source": [
    "imshow(data[2100][0]) #Image before resizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-26T09:45:48.617706Z",
     "start_time": "2020-08-26T09:45:48.280595Z"
    }
   },
   "outputs": [],
   "source": [
    "transform224 = transforms.Compose([transforms.Resize((224,224)), transforms.ToTensor()])\n",
    "data = ImageFolder(path, transform224)\n",
    "imshow(data[2100][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-26T09:45:48.939845Z",
     "start_time": "2020-08-26T09:45:48.619700Z"
    }
   },
   "outputs": [],
   "source": [
    "transform448 = transforms.Compose([transforms.Resize((448,448)), transforms.ToTensor()])\n",
    "data = ImageFolder(path, transform448)\n",
    "imshow(data[2100][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute mean and standard deviation of each RGB channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-26T09:53:04.567727Z",
     "start_time": "2020-08-26T09:51:43.098396Z"
    }
   },
   "outputs": [],
   "source": [
    "red,green,blue = [],[],[]\n",
    "\n",
    "for i in range(len(data)):\n",
    "    temp0 = data[i][0][0].numpy()\n",
    "    temp1 = data[i][0][1].numpy()\n",
    "    temp2 = data[i][0][2].numpy()\n",
    "    red.append(temp0)\n",
    "    green.append(temp1)\n",
    "    blue.append(temp2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-26T09:53:29.349775Z",
     "start_time": "2020-08-26T09:53:20.210211Z"
    }
   },
   "outputs": [],
   "source": [
    "red,green,blue = np.array(red)[0].flatten(),np.array(green)[0].flatten(),np.array(blue)[0].flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-26T09:53:30.943510Z",
     "start_time": "2020-08-26T09:53:30.900624Z"
    }
   },
   "outputs": [],
   "source": [
    "r_mean,r_sd = red.mean(),np.sqrt(red.var())\n",
    "g_mean,g_sd = green.mean(),np.sqrt(green.var())\n",
    "b_mean,b_sd = blue.mean(),np.sqrt(blue.var())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split into train and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-26T06:01:25.850244Z",
     "start_time": "2020-08-26T06:01:25.845257Z"
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "shuffle = np.random.permutation(no_of_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-26T06:01:28.844873Z",
     "start_time": "2020-08-26T06:01:28.840883Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_folder(data):\n",
    "    return data.split('/')[10].split('\\\\')[1] + '/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-26T06:01:31.465957Z",
     "start_time": "2020-08-26T06:01:31.454986Z"
    }
   },
   "outputs": [],
   "source": [
    "lst_folder = list(map(get_folder, files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-26T06:01:31.849931Z",
     "start_time": "2020-08-26T06:01:31.841951Z"
    }
   },
   "outputs": [],
   "source": [
    "lst_folder = list(set(lst_folder))\n",
    "len(lst_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 101 categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-26T11:07:08.678150Z",
     "start_time": "2020-08-26T11:07:08.674161Z"
    }
   },
   "outputs": [],
   "source": [
    "path = 'C:/Users/Yeonkang/Desktop/Deep_Learning/Image_Recognition/Vanilla_CNN/Python/data/101_ObjectCategories'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-26T06:02:02.549432Z",
     "start_time": "2020-08-26T06:02:02.503513Z"
    }
   },
   "outputs": [],
   "source": [
    "os.mkdir(os.path.join(path,'train'))\n",
    "os.mkdir(os.path.join(path,'valid'))\n",
    "\n",
    "for t in ['train','valid']:\n",
    "    for folder in lst_folder:\n",
    "        os.mkdir(os.path.join(path,t,folder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-26T06:02:11.918868Z",
     "start_time": "2020-08-26T06:02:11.545331Z"
    }
   },
   "outputs": [],
   "source": [
    "for i in shuffle[:677]:\n",
    "    folder = files[i].split('/')[10].split('\\\\')[1]\n",
    "    image = files[i].split('/')[10].split('\\\\')[2]\n",
    "    os.rename(files[i], os.path.join(path,'valid',folder,image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-26T06:03:02.826351Z",
     "start_time": "2020-08-26T06:02:58.452650Z"
    }
   },
   "outputs": [],
   "source": [
    "for i in shuffle[677:]:\n",
    "    folder = files[i].split('/')[10].split('\\\\')[1]\n",
    "    image = files[i].split('/')[10].split('\\\\')[2]\n",
    "    os.rename(files[i], os.path.join(path,'train',folder,image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-26T11:08:36.836425Z",
     "start_time": "2020-08-26T11:08:36.779546Z"
    }
   },
   "outputs": [],
   "source": [
    "simple_transform = transforms.Compose([transforms.Resize((448,448)), transforms.ToTensor(), \n",
    "                                     transforms.Normalize([r_mean,g_mean,b_mean],[r_sd,g_sd,b_sd])])\n",
    "train = ImageFolder(os.path.join(path,'train'), simple_transform)\n",
    "valid = ImageFolder(os.path.join(path,'valid'), simple_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-26T11:07:14.169616Z",
     "start_time": "2020-08-26T11:07:14.158271Z"
    }
   },
   "outputs": [],
   "source": [
    "train.class_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-26T09:55:19.545375Z",
     "start_time": "2020-08-26T09:55:19.538387Z"
    }
   },
   "outputs": [],
   "source": [
    "def imshow(inp):\n",
    "    inp = inp.numpy().transpose((1,2,0))\n",
    "    mean,std = np.array([r_mean,g_mean,b_mean]),np.array([r_sd,g_sd,b_sd])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp,0,1)\n",
    "    plt.imshow(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-26T09:55:20.441940Z",
     "start_time": "2020-08-26T09:55:20.163688Z"
    }
   },
   "outputs": [],
   "source": [
    "imshow(train[1000][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-26T09:55:21.180658Z",
     "start_time": "2020-08-26T09:55:21.175676Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data_gen = torch.utils.data.DataLoader(train, batch_size=16, shuffle=True, num_workers=3)\n",
    "valid_data_gen = torch.utils.data.DataLoader(valid, batch_size=16, shuffle=True, num_workers=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build vanilla CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-26T09:55:26.077611Z",
     "start_time": "2020-08-26T09:55:26.069632Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 10, kernel_size=5, stride=1, padding=0)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5, stride=1, padding=0)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(237620, 5000)\n",
    "        self.fc2 = nn.Linear(5000,500)\n",
    "        self.fc3 = nn.Linear(500,101)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x),2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)),2))\n",
    "        x = x.view(x.size(0),-1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc3(x)\n",
    "        return F.log_softmax(x,dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. convolutional layer1 - max pooling - ReLU activation\n",
    "2. convolutional layer2 - dropout - max pooling - ReLU activation\n",
    "3. view\n",
    "4. linear layer1 - ReLU activation\n",
    "5. dropout\n",
    "6. linear layer2 - ReLU activation\n",
    "7. dropout\n",
    "8. linear layer3\n",
    "9. softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-26T09:55:29.031744Z",
     "start_time": "2020-08-26T09:55:29.023765Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "\n",
    "def fit(epoch, model, data_loader, phase='training', volatile=False):\n",
    "    if phase == 'trainig':\n",
    "        model.train()\n",
    "    if phase == 'validation':\n",
    "        model.eval()\n",
    "        volatile = True\n",
    "    running_loss = 0.0\n",
    "    running_correct = 0\n",
    "    for batch_idx, (data,target) in enumerate(data_loader):\n",
    "        if is_cuda:\n",
    "            data,garget = data.cuda(),target.cuda()\n",
    "        data,target = Variable(data,volatile),Variable(target)\n",
    "        if phase == 'training':\n",
    "            optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output,target)\n",
    "        \n",
    "        running_loss += F.nll_loss(output, target, reduction='mean').data\n",
    "        preds = output.data.max(dim=1, keepdim=True)[1]\n",
    "        running_correct += preds.eq(target.data.view_as(preds)).cpu().sum()\n",
    "        if phase == 'training':\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "    loss = running_loss/len(data_loader.dataset)\n",
    "    accuracy = 100. * running_correct.item()/len(data_loader.dataset)\n",
    "    \n",
    "    print(f'{phase} loss is {loss:{5}.{2}} and {phase} accuracy is {running_correct}/{len(data_loader.dataset)}{accuracy:{10}.{4}}')\n",
    "    return loss,accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-26T09:55:54.069160Z",
     "start_time": "2020-08-26T09:55:44.031434Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "model = Net()\n",
    "if is_cuda:\n",
    "    model.cuda()\n",
    "    \n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.5)\n",
    "train_losses,train_accuracy = [],[]\n",
    "val_losses,val_accuracy = [],[]\n",
    "\n",
    "for epoch in range(1,20):\n",
    "    train_epoch_loss,train_epoch_accuracy = fit(epoch, model, train_data_gen, phase='training')\n",
    "    val_epoch_loss,val_epoch_accuracy = fit(epoch, model, valid_data_gen, phase='validation')\n",
    "    train_losses.append(train_epoch_loss)\n",
    "    train_accuracy.append(train_epoch_accuracy)\n",
    "    val_losses.append(val_epoch_loss)\n",
    "    val_accuracy.append(val_epoch_accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
